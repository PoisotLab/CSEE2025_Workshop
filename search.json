[
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup and Prerequesites",
    "section": "",
    "text": "Here‚Äôs a list of instructions to setup your computer for the workshop."
  },
  {
    "objectID": "setup.html#installing-git",
    "href": "setup.html#installing-git",
    "title": "Setup and Prerequesites",
    "section": "Installing git",
    "text": "Installing git\nMake sure you have git installed."
  },
  {
    "objectID": "setup.html#installing-julia",
    "href": "setup.html#installing-julia",
    "title": "Setup and Prerequesites",
    "section": "Installing Julia",
    "text": "Installing Julia\nCopy and paste the following command to install Julia, and the Julia version manager juliaup.\ncurl -fsSL https://install.julialang.org | sh"
  },
  {
    "objectID": "setup.html#installing-packages",
    "href": "setup.html#installing-packages",
    "title": "Setup and Prerequesites",
    "section": "Installing Packages",
    "text": "Installing Packages\nNext, from a terminal, start Julia by typing julia and pressing enter. Then, run the following lines.\n\nusing Pkg\nPkg.add([\n    \"SpeciesDistributionToolkit\",\n    \"CairoMakie\",\n    \"Dates\",\n    \"PrettyTables\",\n    \"DataFrames\",\n    \"IJulia\"\n])\n\nThen, copy and paste the following layer to download the environmental predictors ahead of time (to avoid everyone attempting to download them at once on hotel Wi-Fi). This may take several minutes, depending on your internet connection.\n\nusing SpeciesDistributionToolkit\nusing IJulia\n\ninstallkernel(\"julia\")\n\n[\n    SDMLayer(RasterData(CHELSA2, BioClim), layer=\"BIO$i\", left=40, right=43, bottom=30, top=35)\n    for i in 1:19\n]"
  },
  {
    "objectID": "setup.html#installing-vscode",
    "href": "setup.html#installing-vscode",
    "title": "Setup and Prerequesites",
    "section": "Installing VSCode",
    "text": "Installing VSCode\nInstall VSCode from here.\nOnce VSCode is install It‚Äôs also recommended you install the Julia extension for VSCode here"
  },
  {
    "objectID": "setup.html#installing-quarto",
    "href": "setup.html#installing-quarto",
    "title": "Setup and Prerequesites",
    "section": "Installing Quarto",
    "text": "Installing Quarto\nInstall Quarto from here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "",
    "text": "using Pkg\nPkg.activate(@__DIR__)\nusing Random\nRandom.seed!(1234567)\n\n  Activating project at `~/Code/Workspaces/InterpretableSDMs_CSEE2025`\n\n\nTaskLocalRNG()\n\n\n\nusing SpeciesDistributionToolkit\nusing CairoMakie\nusing Dates\nusing PrettyTables\nusing Statistics\nusing DataFrames\nconst SDT = SpeciesDistributionToolkit\n\nSpeciesDistributionToolkit"
  },
  {
    "objectID": "index.html#downloading-polygon-data",
    "href": "index.html#downloading-polygon-data",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Downloading Polygon Data",
    "text": "Downloading Polygon Data\nLet‚Äôs start by downloading a polygon for the border of Switzerland.\n\nosm_provider = PolygonData(OpenStreetMap, Places)\nswitzerland = getpolygon(osm_provider, place=\"Switzerland\")\n\nFeatureCollection with 1 features, each with 0 properties\n\n\nWe can confirm we downloaded the right data by visualizing it. All visualizations in this tutorial will use the Makie library1.\n1¬†Makie uses various ‚Äúbackends‚Äù to produce figures, depending on the desired output format. We ran using CairoMakie to use the Cairo backend, which is used for producing publication quality PNGs and vector graphics.\nlines(switzerland)\n\n\n\n\n\n\n\n\nLooks good! Now we‚Äôll load the environmental data we‚Äôll use."
  },
  {
    "objectID": "index.html#downloading-environmental-data",
    "href": "index.html#downloading-environmental-data",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Downloading Environmental Data",
    "text": "Downloading Environmental Data\nWe‚Äôll download environment data from CHELSA, which provides 19 bioclimatic layers at 1km\\(^2\\) resolution. The interface for downloading raster data is similar to polygon data ‚Äî first we define a RasterData provider[^rasterdata] which takes in the database (CHELSA2) and particular dataset (BioClim) to download.\n2: A full list of databases, and the datasets they provide, is available here, and in the ‚ÄúDatasets‚Äù tab in the top navigation bar.\n2¬†rasterdata\nchelsa_provider = RasterData(CHELSA2, BioClim)\n\nRasterData{CHELSA2, BioClim}(CHELSA2, BioClim)\n\n\nWe can use the layerdescriptions method to list the names of all of the layers provided by chelsa_provider, along with their descriptions.\n\nlayerdescriptions(chelsa_provider)\n\nDict{String, String} with 19 entries:\n  \"BIO8\"  =&gt; \"Mean Temperature of Wettest Quarter\"\n  \"BIO14\" =&gt; \"Precipitation of Driest Month\"\n  \"BIO16\" =&gt; \"Precipitation of Wettest Quarter\"\n  \"BIO18\" =&gt; \"Precipitation of Warmest Quarter\"\n  \"BIO19\" =&gt; \"Precipitation of Coldest Quarter\"\n  \"BIO10\" =&gt; \"Mean Temperature of Warmest Quarter\"\n  \"BIO12\" =&gt; \"Annual Precipitation\"\n  \"BIO13\" =&gt; \"Precipitation of Wettest Month\"\n  \"BIO2\"  =&gt; \"Mean Diurnal Range (Mean of monthly (max temp - min temp))\"\n  \"BIO11\" =&gt; \"Mean Temperature of Coldest Quarter\"\n  \"BIO6\"  =&gt; \"Min Temperature of Coldest Month\"\n  \"BIO4\"  =&gt; \"Temperature Seasonality (standard deviation √ó100)\"\n  \"BIO17\" =&gt; \"Precipitation of Driest Quarter\"\n  \"BIO7\"  =&gt; \"Temperature Annual Range (BIO5-BIO6)\"\n  \"BIO1\"  =&gt; \"Annual Mean Temperature\"\n  \"BIO5\"  =&gt; \"Max Temperature of Warmest Month\"\n  \"BIO9\"  =&gt; \"Mean Temperature of Driest Quarter\"\n  \"BIO3\"  =&gt; \"Isothermality (BIO2/BIO7) (√ó100)\"\n  \"BIO15\" =&gt; \"Precipitation Seasonality (Coefficient of Variation)\"\n\n\nTo download a layer, we use the SDMLayer constructor, and pass the specific name of the we want layer keyword argument. We also pass the bounding box of the region we want with the left, right, bottom and top keywords.\nFor example, to download BIO1 (mean annual temperature) at longitudes from 40¬∞ to 43¬∞, and latitudes from 30¬∞ to 35¬∞, we run\n\nSDMLayer(chelsa_provider, layer=\"BIO1\", left=40, right=43, bottom=30, top=35)\n\nüó∫Ô∏è  A 601 √ó 361 layer with 216961 UInt16 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nWe want to download each layer for the bounding box of Switzerland. We can obtain this by using the boundingbox method3\n3¬†Note that we use SDT.boundingbox because boundingbox shares a name with another method in CairoMakie, so we have to specificy which boundingbox method we mean.\nSDT.boundingbox(switzerland)\n\n(left = 5.955911159515381, right = 10.492294311523438, bottom = 45.81795883178711, top = 47.80845260620117)\n\n\nNote that this returns a named-tuple with each coordinate named in the same way we need them for downloading a layer. This allows us to directly input the result of SDT.boundingbox into SDMLayer using splatting4, e.g.\n4¬†Splatting refers to adding ... after a collection of items (like a vector or tuple), which results in them each being processed as sequential arguments. For example, if x=[1,2,3] and you call f(x...), this is equivalent to f(1,2,3).\nSDMLayer(chelsa_provider; layer=\"BIO1\", SDT.boundingbox(switzerland)...)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 131040 UInt16 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nWe can then load all 19 bioclimatic variables by using layers, which returns a list of the names of each layer provided by chelsa_provider, e.g.\n\nlayers(chelsa_provider)\n\n19-element Vector{String}:\n \"BIO1\"\n \"BIO2\"\n \"BIO3\"\n \"BIO4\"\n \"BIO5\"\n \"BIO6\"\n \"BIO7\"\n \"BIO8\"\n \"BIO9\"\n \"BIO10\"\n \"BIO11\"\n \"BIO12\"\n \"BIO13\"\n \"BIO14\"\n \"BIO15\"\n \"BIO16\"\n \"BIO17\"\n \"BIO18\"\n \"BIO19\"\n\n\nWe can then load them all in a single line using an in-line for loop.\n\n\n\n\n\n\nNote on downloading and storing layers\n\n\n\n\n\nNote that the first time you run the following lines, the entirety of each layer will be downloaded and cached. This means the first time you run this line, it will take several minutes, but every subsequent time will be nearly instant, because the layers are saved in SimpleSDMDataset‚Äôs cache (by default, this is located in ~/.julia/SimpleSDMDatasets/).\n\n\n\n\nenv_covariates = SDMLayer{Float32}[\n    SDMLayer(\n        chelsa_provider; \n        layer = layername,\n        SDT.boundingbox(switzerland)...\n    )\n    for layername in layers(chelsa_provider)\n]\n\n19-element Vector{SDMLayer{Float32}}:\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (131040 Float32 cells)\n\n\n\n\n\n\n\n\nOther ways to iterate over the layers we want to download\n\n\n\n\n\nNote that there are many different ways to do iteration in Julia, not just the in-line for loop used above.\n\n\nUsing a conventional for loop with indices\nenv_covariates = SDMLayer{Float32}[]\nfor i in 1:19\n    push!(env_covariates, \n        SDMLayer(\n            chelsa_provider; \n            layer = \"BIO$i\", \n            SDT.boundingbox(switzerland)...\n        )\n    )\nend\n\n\n\n\nUsing map with layer names\nenv_covariates = map(\n    layername -&gt; Float32.(SDMLayer(\n        chelsa_provider; \n        layer = layername,\n        SDT.boundingbox(switzerland)...\n    )),\n    layers(chelsa_provider)\n);\n\n\n\n\n\nNow we can visualize the first layer, and our polygon. We‚Äôll plot the first environmental layer with heatmap, and we‚Äôll pass color=:white and linewidth=3 to make our polygon easier to see.\n\nheatmap(env_covariates[begin])\nlines!(switzerland, color=:white, linewidth=3)\ncurrent_figure()\n\n\n\n\n\n\n\n\nNote that although our raster has the same extent as our polygon, it extends outside our polygon‚Äôs border. We can fix this with the mask! method.\n\nMasking the environmental layers\n\nmask!(env_covariates, switzerland)\n\n19-element Vector{SDMLayer{Float32}}:\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n\n\nand we can verify this worked by plotting it again:\n\nheatmap(env_covariates[begin])\nlines!(switzerland, color=:red, linewidth=3)\ncurrent_figure()\n\n\n\n\n\n\n\n\nLet‚Äôs plot a few of them.\n\n\n\n\n\n\nCode for plotting multiple layers\n\n\n\n\n\n\nlayers_to_plot = [1, 4, 12, 15]\n\nf = Figure()\nfor (i,ci) in enumerate(CartesianIndices((1:2,1:2)))\n    this_layer = layers(chelsa_provider)[layers_to_plot[i]]\n    ax = Axis(\n        f[ci[1], ci[2]], \n        title=layerdescriptions(chelsa_provider)[this_layer], \n        titlesize=12\n    )\n    heatmap!(ax, env_covariates[layers_to_plot[i]])\n    hidedecorations!(ax)\n    hidespines!(ax)\nend"
  },
  {
    "objectID": "index.html#downloading-occurrence-data",
    "href": "index.html#downloading-occurrence-data",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Downloading occurrence data",
    "text": "Downloading occurrence data\nNow we‚Äôll use the GBIF.jl subpackage to download occurrence data from the Global Biodiversity Information Facility (GBIF) for our species, Turdus torquatus. We do this with the taxon method.\n\nouzel = taxon(\"Turdus torquatus\")\n\nGBIF taxon -- Turdus torquatus\n\n\nWe‚Äôll then use the occurrences method to setup a data download from GBIF. We pass the taxon, ouzel, and an environmental covariate (with first(env_covariates)) representing the extent from which we want to download occurrences. The function also takes keyword arguments that are specified in the GBIF API.\n\npresences = occurrences(\n    ouzel,\n    first(env_covariates),\n    \"occurrenceStatus\" =&gt; \"PRESENT\",\n    \"limit\" =&gt; 300,\n    \"country\" =&gt; \"CH\",\n    \"datasetKey\" =&gt; \"4fa7b334-ce0d-4e88-aaae-2e0c138d049e\",\n)\n\nGBIF records: downloaded 300 out of 1404\n\n\nNote that this only downloads the first 300 occurrences, because the total number of records can vary drastically depending on the species and extent, and the GBIF streaming API has a hard limit at 200000 records, and querying large amounts of using the streaming API is woefully inefficient. For data volumes above 10000 observations, the suggested solution is to rely on the download interface on GBIF.\nWe can use the count method to determine how many total records match our criteria\n\ncount(presences)\n\n1404\n\n\nBecause this is a reasonable number, we can download the rest of the occurrences using a while loop, and a the occurrences! method to iterate and download the remaining occurrences.\n\nwhile length(presences) &lt; count(presences)\n    occurrences!(presences)\nend\n\nGBIF has a built-in Table.jl API, which means we can easily convert the occurrence records to a DataFrame:\n\nDataFrame(presences)\n\n1404√ó29 DataFrame1379 rows omitted\n\n\n\nRow\nkey\ndatasetKey\ndataset\npublishingOrgKey\npublishingCountry\ninstitutionCode\nprotocol\ncountryCode\ncountry\nbasisOfRecord\nindividualCount\nlatitude\nlongitude\nprecision\nuncertainty\ngeodetic\ndate\nidentified\nissues\ntaxonKey\nrank\ntaxon\ngeneric\nepithet\nvernacular\nscientific\nobserver\nlicense\npresence\n\n\n\nInt64\nString\nMissing\nString\nString\nString\nString\nString\nString\nSymbol\nInt64?\nFloat64\nFloat64\nMissing\nMissing\nString\nMissing\nMissing\nArray‚Ä¶\nInt64\nString\nGBIFTaxon\nString\nString\nString\nString\nString\nString\nBool\n\n\n\n\n1\n4709728505\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.3404\n7.63405\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr788756\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n2\n4631294555\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n3\n47.1648\n9.19779\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1473331\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n3\n4717153698\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.3878\n8.02234\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1538171\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n4\n4703405324\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.3878\n8.02234\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr2869500\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n5\n4698992061\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n3\n47.1861\n9.35102\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr2670291\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n6\n4611055512\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n6\n46.8433\n7.98554\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr2692703\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n7\n4794340181\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.5887\n6.17083\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1538171\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n8\n4639401120\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n11\n46.8154\n9.76794\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1473331\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n9\n4779612275\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n7\n46.7888\n6.488\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr109021\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n10\n4723809355\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n4\n47.0041\n9.50994\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr2900560\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n11\n4724185634\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n6\n46.9023\n8.67436\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:COORDINATE_ROUNDED, :CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1586679\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n12\n4799483908\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n6\n46.7945\n9.67675\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr3040942\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n13\n4798123478\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n15\n46.6092\n6.21726\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr2670291\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\n1393\n4320365329\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\nmissing\n46.3899\n8.06182\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1479734\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1394\n258866137\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\nmissing\n46.0135\n7.74446\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr17450\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1395\n258565537\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\nmissing\n46.5014\n9.8353\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr17450\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1396\n3292306100\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.3063\n8.01213\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr904825\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1397\n1791714342\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\nmissing\n46.6925\n9.40155\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr439300\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1398\n602573529\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n15\n46.6035\n8.51234\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr86442\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1399\n3281963623\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.3063\n8.01213\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr904825\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1400\n2127587072\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n4\n46.5866\n7.9605\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr137776\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1401\n2793845474\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.5223\n6.94705\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr293417\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1402\n2726803858\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\n1\n46.6671\n10.1934\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1051392\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1403\n2792111865\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\nmissing\n45.992\n7.70887\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr201030\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n1404\n2799732429\n4fa7b334-ce0d-4e88-aaae-2e0c138d049e\nmissing\ne2e717bf-551a-4917-bdc9-4fa0f342c530\nCH\nCLO\nDWC_ARCHIVE\nCH\nSwitzerland\nHUMAN_OBSERVATION\nmissing\n46.5591\n7.89209\nmissing\nmissing\nWGS84\nmissing\nmissing\n[:CONTINENT_DERIVED_FROM_COORDINATES, :TAXON_MATCH_TAXON_CONCEPT_ID_IGNORED]\n7865305\nSPECIES\nGBIF taxon -- Turdus torquatus\\n\nTurdus\ntorquatus\nRing Ouzel\nTurdus torquatus Linnaeus, 1758\nobsr1426731\nhttp://creativecommons.org/licenses/by/4.0/legalcode\ntrue\n\n\n\n\n\n\nHowever, SDeMo is designed to work with the result from GBIF directly. For example, we can plot them with scatter!\n\nlines(switzerland)\nscatter!(presences)\ncurrent_figure()\n\n\n\n\n\n\n\n\nWe can also convert the occurrences into a raster with true values at the location of occurrences using the mask function. This will be useful for us in the next section.\n\npresencelayer = mask(first(env_covariates), presences)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Bool cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs"
  },
  {
    "objectID": "index.html#computing-statistics-with-occurrences",
    "href": "index.html#computing-statistics-with-occurrences",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Computing statistics with occurrences",
    "text": "Computing statistics with occurrences\nHere, we‚Äôll show how we can work with occurrence data and polygons. First, we‚Äôll download data on the Swiss cantons (states), using the GADM polygon database.\n\ngadm_provider = PolygonData(GADM, Countries)\nswiss_states = getpolygon(gadm_provider; country=\"CHE\", level=1)\n\nFeatureCollection with 26 features, each with 2 properties\n\n\nNext we‚Äôll plot each state along with presence records.\n\nlines(switzerland, color=:black)\nlines!(swiss_states, color=:grey60)\nscatter!(presencelayer)\ncurrent_figure()\n\n\n\n\n\n\n\n\nNext we‚Äôll use the byzone method to compute the total number of presences in each state. We pass sum as the method to apply to each region, and presencelayer as the layer to apply sum to.\n\npres_per_state = Dict(\n    byzone(sum, presencelayer, [x for x in swiss_states], [x.properties[\"Name\"] for x in swiss_states])\n)\n\nDict{String, Int64} with 24 entries:\n  \"Gen√®ve\"           =&gt; 0\n  \"Uri\"              =&gt; 29\n  \"Ticino\"           =&gt; 37\n  \"Thurgau\"          =&gt; 0\n  \"Zug\"              =&gt; 0\n  \"Schwyz\"           =&gt; 13\n  \"Lucerne\"          =&gt; 20\n  \"Obwalden\"         =&gt; 24\n  \"Vaud\"             =&gt; 56\n  \"Nidwalden\"        =&gt; 10\n  \"SanktGallen\"      =&gt; 68\n  \"Graub√ºnden\"       =&gt; 164\n  \"Neuch√¢tel\"        =&gt; 4\n  \"Bern\"             =&gt; 93\n  \"Fribourg\"         =&gt; 29\n  \"Basel-Landschaft\" =&gt; 1\n  \"Aargau\"           =&gt; 0\n  \"Z√ºrich\"           =&gt; 1\n  \"Valais\"           =&gt; 134\n  ‚ãÆ                  =&gt; ‚ãÆ\n\n\nFinally, we‚Äôll plot the total number of occurrences in each state as a bar chart.\n\n\n\n\n\n\nCode for plotting presences by state\n\n\n\n\n\n\npresence_cts = collect(values(pres_per_state))\nsort_idx = sortperm(presence_cts)\nstate_names = collect(keys(pres_per_state))\n\n\nf = Figure()\nax = Axis(\n    f[1,1], \n    xlabel = \"Number of Occurrences\",\n    ylabel = \"State\",\n    yticks=(1:length(state_names), state_names[sort_idx])\n)\nbarplot!(ax, presence_cts[sort_idx], direction=:x)\n\nPlot{barplot, Tuple{Vector{Point{2, Float64}}}}"
  },
  {
    "objectID": "index.html#associating-environmental-covariates-with-occurrences",
    "href": "index.html#associating-environmental-covariates-with-occurrences",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Associating Environmental Covariates with Occurrences",
    "text": "Associating Environmental Covariates with Occurrences\nNext, we‚Äôll show how we associate the data in our environmental covariates with each occurrence point. First, let‚Äôs select the environmental covariates that represent mean annual temperature (BIO1), and annual precipitation (BIO12).\n\ntemperature, precipitation = env_covariates[[1,12]]\n\n2-element Vector{SDMLayer{Float32}}:\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float32 cells)\n\n\nWe can simply index the layers by the presences object to select the value of the covariate at each location.\n\ntemp, precip = temperature[presences], precipitation[presences]\n\n(Float32[2779.0, 2767.0, 2741.0, 2741.0, 2775.0, 2760.0, 2798.0, 2731.0, 2795.0, 2828.0  ‚Ä¶  2736.0, 2802.0, 2785.0, 2762.0, 2802.0, 2734.0, 2796.0, 2739.0, 2714.0, 2763.0], Float32[12204.0, 25308.0, 16461.0, 16461.0, 20484.0, 20710.0, 18301.0, 17158.0, 16509.0, 10499.0  ‚Ä¶  15375.0, 10211.0, 11675.0, 22840.0, 10211.0, 20742.0, 17484.0, 11090.0, 16431.0, 18676.0])\n\n\nNote that CHELSA doesn‚Äôt provide data in commonly used units ‚Äî the transformations to convert them into typical units can be found in their [documentation]. The relevant transformations for temperature and precipitation are applied below.\ntemp = 0.1temp .- 271\nprecip = 0.1precip\nFinally, we can add a silhoutte of our taxon to the plot by downloading it using the Phylopic subpackage.\n\ntaxon_silhoeutte = Phylopic.imagesof(ouzel)\n\nPhylopicSilhouette(\"Turdus migratorius\", Base.UUID(\"7be55586-e993-4eb3-88a0-9ec7a2ba0c7d\"))\n\n\nThis can all be visualized using the code below, which shows a clear negative correlation between temperature and precipitation at the occurrence locations.\n\nf = Figure()\nax = Axis(\n    f[1,1], \n    xlabel=\"Annual mean temperature (¬∞C)\", \n    ylabel=\"Annual precipitation (kg√óm‚Åª¬≤)\"\n)\nscatter!(ax, 0.1temperature[presences].-271, 0.1precipitation[presences], color=(:seagreen4, 0.7))\nsilhouetteplot!(ax, -5., 1000.0, taxon_silhoeutte; markersize=70)\nf"
  },
  {
    "objectID": "index.html#sampling-pseudo-absences",
    "href": "index.html#sampling-pseudo-absences",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Sampling Pseudo-Absences",
    "text": "Sampling Pseudo-Absences\nAll of the models we use for binary classification, including Naive-Bayes, require presence-absence data. However, for the vast majority of species, we don‚Äôt have records of true species absences because these typically expensive monitoring programs, in contrast to the widespread availability of presence data on GBIF, which is largely crowdsourced from community science platforms like iNaturalist.\nTo deal with this, a widespread method is generating pseudo-absences, which rely on hueristics to select sites where it is very unlikely that the target species is present. There is a deep literature on methods to select the locations and number of pseudoabsences (tk cites). Here we will use a method called background thickening, which means the probability a given location is marked as a pseudoabsence grows with the minimum distance to nearest presence.\nWe can implement background thickening this using the pseudoabsencemask method, first with the DistanceToEvent technique, which generates a layer where each value is the distance (in kilometers) to the nearest presence record.\n\nbackground = pseudoabsencemask(DistanceToEvent, presencelayer)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nWe can then visualize this using heatmap.\n\nheatmap(background)\n\n\n\n\n\n\n\n\nWe could draw pseudoabsences from this, but it is also typically a good idea to add a buffer around each presence, which are not allowed to include pseudoabsences. The justification for this is it‚Äôs unlikely to be truly absent in locations very close to an observed presence. Here, we‚Äôll use a buffer distance of 4 kilometers, and mask those regions out using the nodata method.\n\nbuffer_distance = 4 # In kilometers\nbuffered_background = nodata(background, d -&gt; d &lt; buffer_distance)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 45448 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nand we‚Äôll visualize it to show the added buffer\n\nheatmap(buffered_background)\nscatter!(presences, markersize=4, color=colorant\"#e79154\")\ncurrent_figure()\n\n\n\n\n\n\n\n\nFinally, we‚Äôll sample pseudoabsences using the backgroundpoints method. We‚Äôll choose to sample twice as many pseudoabsences as there are presences. In real workflows, it‚Äôs important to determine the sensitivity of a model to the number of pseudoabsences, but given this tutorial is focused on interpretable machine learning, we‚Äôll stick with number of pseudoabsences for each example.\n\nnum_pseudoabsences = 2sum(presencelayer)\npseudoabsences = backgroundpoints(buffered_background, num_pseudoabsences)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 45448 Bool cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nFinally, we can visualize the pseudoabsences using scatter!, just as we would for presences. Below, presences are in orange, and pseudoabsences are in grey.\n\nlines(switzerland, color=:black)\nscatter!(presencelayer, color=colorant\"#e79154\", markersize=7)\nscatter!(pseudoabsences, color=colorant\"#bbb\", markersize=5)\ncurrent_figure()\n\n\n\n\n\n\n\n\nWe can see there is a clear geographic distinction in the regions where presences and absences are, but crucially we need them to be if different regions of environmental space.\nWe visualize the density of presences and absences in environmental space below.\n\n\n\n\n\n\nCode for plotting density in environmental space\n\n\n\n\n\n\nabcol = colorant\"#bbb\"\nprcol = colorant\"#e79154\"\n\n_range = (\n    absent = abcol,\n    present = prcol,\n    absentbg = (abcol, 0.2),\n    presentbg = (prcol, 0.2),\n)\nbkcol = (\n    nodata = colorant\"#DDDDDD\",\n    generic = colorant\"#222222\",\n    sdm = _range,\n)\n\ntemp_idx, precip_idx = 1, 12\n\ntmp, precip = 0.1env_covariates[temp_idx] - 273.15, 0.1env_covariates[precip_idx]\n\ntemp_pres = tmp.grid[presencelayer.grid]\ntemp_abs = tmp.grid[pseudoabsences.grid]\n \nprecip_pres = precip.grid[presencelayer.grid]\nprecip_abs = precip.grid[pseudoabsences.grid]\n \nf = Figure()\n\ngl = f[1,1] = GridLayout()\n\naxtemp = Axis(gl[1,1])\ndensity!(axtemp, temp_pres, color=bkcol.sdm.presentbg, strokecolor=bkcol.sdm.present, strokewidth=1)\ndensity!(axtemp, temp_abs, color=bkcol.sdm.absentbg, strokecolor=bkcol.sdm.absent, strokewidth=1)\n\naxprec = Axis(gl[2,2])\ndensity!(axprec, precip_pres, color=bkcol.sdm.presentbg, strokecolor=bkcol.sdm.present, strokewidth=1, direction=:y)\ndensity!(axprec, precip_abs, color=bkcol.sdm.absentbg, strokecolor=bkcol.sdm.absent, strokewidth=1, direction=:y)\n\naxboth = Axis(gl[2,1], xlabel=\"Mean air temperature (¬∞C)\", ylabel = \"Annual precipitation (kg m‚Åª¬≤)\")\nscatter!(axboth, temp_abs, precip_abs, color=bkcol.sdm.absent, markersize=4, label=\"Pseudo-absence\")\nscatter!(axboth, temp_pres, precip_pres, color=bkcol.sdm.present, markersize=4, label=\"Presence\")\n\naxislegend(position = :lb)\n\nhidespines!(axtemp, :l, :r, :t)\nhidespines!(axprec, :b, :r, :t)\nhidedecorations!(axtemp, grid = true)\nhidedecorations!(axprec, grid = true)\nylims!(axtemp, low = 0)\nxlims!(axprec, low = 0)\ncolgap!(gl, 0)\nrowgap!(gl, 0)\n\ncolsize!(gl, 1, Relative(5/6))\nrowsize!(gl, 2, Relative(5/6))\n\ncurrent_figure()"
  },
  {
    "objectID": "index.html#training-a-simple-sdm",
    "href": "index.html#training-a-simple-sdm",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Training a Simple SDM",
    "text": "Training a Simple SDM\nNow that we have presences and pseudoabsences, we are finally ready to train our model.SDeMo uses a single SDM type that chains together the data transformation, the model, and data to fit on.\nWe‚Äôll start by building a classifier using logistic regression that first applies z-scores only to the training data5.\n5¬†It‚Äôs crucial that parameters of the z-score transformation (the mean and standard deviation of the data) for each predictor is only estimated from the training data to avoid introducing data leakage, where information about the data used to evaluate the model accidentally becomes available (‚Äúleaks‚Äù) into the training data. The pipeline applied to SDM objects avoids leakage by default, for all data transformations.\nnb_sdm = SDM(ZScore, Logistic, env_covariates, presencelayer, pseudoabsences)\n\nSDeMo.ZScore ‚Üí SDeMo.Logistic ‚Üí P(x) ‚â• 0.5\n\n\nWith the SDM built, we then call the train! method to actually fit the model to the data.\n\ntrain!(nb_sdm)\n\nSDeMo.ZScore ‚Üí SDeMo.Logistic ‚Üí P(x) ‚â• 0.472\n\n\nLike any binary classifier, Naive-Bayes produces a score between \\(0\\) and \\(1\\) for each prediction, and then selects an optimal threshold \\(\\tau\\). Then, every location with a score less than \\(\\tau\\) is predicted to be false, and above \\(\\tau\\) is predicted to be true.\nWe produce the model‚Äôs predictions using the predict method, and to visualize the raw scores (prior to thresholding), we pass the threshold = false argument.\n\nprd = predict(nb_sdm, env_covariates; threshold = false)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nWe can then visualize the raw score values.\n\nf = Figure()\nax = Axis(f[1,1])\nhm = heatmap!(ax, prd, colorrange=(0,1))\nscatter!(ax, presencelayer, color=:white, markersize=4)\nColorbar(f[1,2], hm, label=\"Score\", ticks=0:0.25:1)\nhidedecorations!(ax)\nhidespines!(ax)\nf\n\n\n\n\n\n\n\n\nBy default, the predict method will apply the optimal threshold to produce a binary range map, but we can do this by passing threshold=true. Thresholding is done by selecting the value of \\(\\tau\\) that maximizes the Matthew‚Äôs Correlation Coefficient.\n\nprd = predict(nb_sdm, env_covariates; threshold = true)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Bool cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nand similarly we can visualize.\n\nf = Figure()\nax = Axis(f[1,1])\nheatmap!(ax, prd, colormap=[:grey75, :seagreen4])\nscatter!(ax, presencelayer, color=:white, markersize=4)\nhidedecorations!(ax)\nhidespines!(ax)\nf"
  },
  {
    "objectID": "index.html#validating-an-sdm",
    "href": "index.html#validating-an-sdm",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Validating an SDM",
    "text": "Validating an SDM\nWe can now assess how well our model is making predictions using crossvalidation. SDeMo provides tools for various forms of crossvalidation, including kfold, leaveoneout, montecarlo (\\(n\\) random validation splits), and holdout (one random validation split).\nHere, we‚Äôll use k-fold validation with 5 folds.\n\nfolds = kfold(nb_sdm, k = 5)\n\n5-element Vector{Tuple{Vector{Int64}, Vector{Int64}}}:\n ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  ‚Ä¶  2054, 2055, 2056, 2057, 2059, 2060, 2061, 2064, 2066, 2067], [243, 153, 213, 466, 625, 170, 38, 473, 249, 66  ‚Ä¶  1868, 980, 1167, 996, 1616, 1466, 1171, 1791, 2001, 1537])\n ([2, 3, 4, 5, 6, 7, 8, 9, 10, 11  ‚Ä¶  2058, 2059, 2060, 2062, 2063, 2064, 2065, 2066, 2067, 2068], [217, 340, 228, 475, 128, 489, 137, 68, 620, 333  ‚Ä¶  1261, 1508, 2008, 1035, 967, 1234, 1690, 1061, 1887, 1668])\n ([1, 2, 4, 5, 6, 7, 9, 11, 12, 13  ‚Ä¶  2057, 2058, 2060, 2061, 2062, 2063, 2065, 2066, 2067, 2068], [549, 87, 167, 480, 318, 155, 299, 284, 490, 186  ‚Ä¶  1335, 1440, 993, 1859, 1894, 1949, 731, 1611, 1658, 1950])\n ([1, 2, 3, 4, 5, 7, 8, 9, 10, 11  ‚Ä¶  2056, 2057, 2058, 2059, 2061, 2062, 2063, 2064, 2065, 2068], [382, 278, 315, 535, 339, 507, 663, 627, 125, 424  ‚Ä¶  1967, 1781, 1165, 1624, 1683, 1148, 2007, 981, 1674, 1761])\n ([1, 3, 6, 8, 10, 11, 12, 13, 14, 15  ‚Ä¶  2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068], [129, 295, 584, 89, 117, 28, 229, 637, 233, 252  ‚Ä¶  1610, 928, 1244, 1222, 1855, 1878, 1994, 814, 1076, 1037])\n\n\nWe then call the crossvalidation method, which fits the model on each fold.\n\ncv = crossvalidate(nb_sdm, folds)\n\n(validation = ConfusionMatrix[[TP: 129, TN 249, FP 25, FN 12], [TP: 125, TN 239, FP 35, FN 15], [TP: 127, TN 239, FP 34, FN 12], [TP: 125, TN 236, FP 38, FN 15], [TP: 120, TN 244, FP 29, FN 20]], training = ConfusionMatrix[[TP: 501, TN 970, FP 124, FN 58], [TP: 505, TN 983, FP 111, FN 55], [TP: 509, TN 979, FP 116, FN 52], [TP: 509, TN 976, FP 118, FN 51], [TP: 507, TN 980, FP 115, FN 53]])\n\n\nNow we can apply various metrics to quantify model performance, and compare it to their expected value from a null model.\nHere, we‚Äôll use Matthew‚Äôs Correlation Coefficient (mcc), and the True-Skill Statistic, and compare our model to a coinflip null model (where each prediction is true or false with equal probability).\n\nmeasures = [mcc, trueskill]\ncvresult = [measure(set) for measure in measures, set in cv]\nnullresult = [measure(null(nb_sdm)) for measure in measures, null in [coinflip]]\npretty_table(\n    hcat(string.(measures), hcat(cvresult, nullresult));\n    alignment = [:l, :c, :c, :c],\n    #backend = Val(:markdown),\n    header = [\"Measure\", \"Validation\", \"Training\", \"Coin-flip\"],\n    formatters = ft_printf(\"%5.3f\", [2, 3, 4, 5]),\n)\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Measure   ‚îÇ Validation ‚îÇ Training ‚îÇ Coin-flip ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ mcc       ‚îÇ   0.757    ‚îÇ  0.779   ‚îÇ  -0.323   ‚îÇ\n‚îÇ trueskill ‚îÇ   0.777    ‚îÇ  0.797   ‚îÇ  -0.323   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
  },
  {
    "objectID": "index.html#smarter-variable-selection",
    "href": "index.html#smarter-variable-selection",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Smarter Variable Selection",
    "text": "Smarter Variable Selection\nAnother feature of SDeMo is various methods for variable selection. In the previous example, we fit our model to all 19 BioClimatic variables. However, there are many good reasons that we might not want to included every variable as a predictor.\nOne is collinearity among predictors, which can cause issues with being able to adaquetly estimate model parameters.\nSDeMo includes various methods for selecting variables, including using the Variance-Inflation Factor (VIF), as well as methods for Forward and Backward variable selection. Here we will use VIF to remove collienar variables.6\n6¬†Methods for variable selection are generally controversial among statisticians. In general, we don‚Äôt recommend using variable selection methods with a single model ‚Äî often, it is a much better alternative to use an ensemble of models, each trained on a subset of predictors. This technique is known as bootstrap aggregation (or bagging), and we will demonstrate it in the next section.We can apply various variable selection methods using the variables! method. For example, we can remove variable one at a time until the maximum VIF is below a provided value (2 in the following example).\n\ndt_sdm = variables!(dt_sdm, StrictVarianceInflationFactor{2.})\n\nSDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.147\n\n\nWe can then use the variables method to list what the selected variables are.\n\nvariables(dt_sdm)\n\n5-element Vector{Int64}:\n  3\n  4\n  8\n 14\n 15\n\n\nNow, we can use train! just as before to fit our decision tree on just the selected variables.\n\ntrain!(dt_sdm)\n\nSDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.147\n\n\nand again use predict! to make our predicted range.\n\nprd = predict(dt_sdm, env_covariates; threshold = false)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nand we can visualize as before\n\nf = Figure(; size = (600, 300))\nax = Axis(f[1, 1]; aspect = DataAspect(), title = \"Prediction (decision tree)\")\nhm = heatmap!(ax, prd; colormap = :linear_worb_100_25_c53_n256, colorrange = (0, 1))\nColorbar(f[1, 2], hm)\nlines!(ax, switzerland; color = :black)\nhidedecorations!(ax)\nhidespines!(ax)\nf"
  },
  {
    "objectID": "index.html#variable-importance",
    "href": "index.html#variable-importance",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Variable Importance",
    "text": "Variable Importance\nVariable importance is quantified in the relative amount a model improves when a given variable \\(i\\) is added, compared to the same model fit on every variable but \\(i\\).\nIn SDeMo, variable importance can be computed using the variableimportance method, applied to a given crossvalidation scheme.\n\nvar_impt = variableimportance(dt_sdm, kfold(dt_sdm, k=20))\n\n5-element Vector{Float64}:\n 0.037896415314614594\n 0.16173839289884473\n 0.24884329607538977\n 0.1529497836009484\n 0.04428583226631949\n\n\nWe can then visualize it with barplot!\n\nf = Figure()\nax = Axis(f[1,1], xticks=(1:length(variables(dt_sdm)), [\"BIO$i\" for i in variables(dt_sdm)]))\nbarplot!(ax, var_impt)\nf"
  },
  {
    "objectID": "index.html#shap-values",
    "href": "index.html#shap-values",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "SHAP Values",
    "text": "SHAP Values\nSHAP values are a method for game-theory adapted adapted to make machine-learning models explainable from CITE TODO. By explainable, we mean that we can contribution of each individual feature on the overall prediction. SHAP is a generalization of a few different methods for interpretability, but the most notable is Locally Interpretable Model Explanations (LIME; CITE TODO). The idea behind LIME (and the other similar methods that SHAP provides a generalizes) is to take a nonlinear, uninterpretable machine learning model, and fit a separate, simpler, model to explain its predictions that is inherently interpretable (like linear regression, where each coefficient directly quantifies the contribution to each variable).\nSHAP values across space can be estimated with the explain method in SDeMo, with the predictors passed as a second argument, and the particular variable to consider as the third argument.\nIn contrast to partial responses, Shapley values are calculated at the scale of a single prediction (not the average value across other predictors), and represent the departure from the average model prediction due to the specific value of the variable of interest for this prediction.\n\nshapley1 = explain(dt_sdm, env_covariates, variables(dt_sdm)[1]; threshold=false)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nWe can then plot the contribution of that variable across space.\n\nf = Figure()\nax = Axis(f[1,1])\nhm = heatmap!(ax, shapley1)\nColorbar(f[1,2], hm, label=\"Contribution of BIO$(variables(dt_sdm)[1]) to prediction score\")\nf\n\n\n\n\n\n\n\n\nWe can also estimate the contributed all at once by not passing any particular variable.\n\nshaps = explain(dt_sdm, env_covariates; threshold=false)\n\n5-element Vector{SDMLayer{Float64}}:\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float64 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float64 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float64 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float64 cells)\n üó∫Ô∏è  A 240 √ó 546 layer (70065 Float64 cells)\n\n\nBy using the mosaic method, we can then compute the most important variable contributing to the overall prediction (as measured by the largest magnitude SHAP value).\n\nmost_impt_feature = mosaic(argmax, map(x -&gt; abs.(x), shaps))\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Int64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nand finally plot\n\nf = Figure(; size = (600, 300))\ncolmap = [colorant\"#E69F00\", colorant\"#56B4E9\", colorant\"#009E73\", colorant\"#D55E00\", colorant\"#CC79A7\", colorant\"#ccc\", colorant\"#101010\"]\nax = Axis(f[1, 1]; aspect = DataAspect())\nheatmap!(ax, most_impt_feature; colormap = colmap)\nlines!(ax, switzerland; color = :black)\nhidedecorations!(ax)\nhidespines!(ax)\nLegend(\n    f[2, 1],\n    [PolyElement(; color = colmap[i]) for i in 1:length(variables(dt_sdm))],\n    [\"BIO$(b)\" for b in variables(dt_sdm)];\n    orientation = :horizontal,\n    nbanks = 1,\n    framevisible = false,\n    vertical = false,\n)\nf"
  },
  {
    "objectID": "index.html#conformal-prediction",
    "href": "index.html#conformal-prediction",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal prediction is another method for interpreting machine learning models. Specifically, it is a form of uncertainty quantification.\nIn contrast to SHAP values and other forms of model explanation, conformal prediction helps with model interpretation, by quantifying how confident we can be in our SDM‚Äôs predictions across space.\nThis works by taking our biary classification model, and turning it into a conformal model. The difference is that unlike our binary classification model, which produces a score between \\(0\\) and \\(1\\) that indicates if given feature is likely to be associated with species presence, a conformal model maps each feature to a credible set of values. Mathematically, a conformal model \\(\\mathcal{C}\\) maps a feature in \\(\\mathbb{R}^k\\) to a set of credible values. \\[\n\\mathcal{C} : \\mathbb{R}^k \\to \\{0\\}, \\{1\\}, \\{0,1\\}\n\\]\nIf a model maps to \\(\\{0,1\\}\\), this means either presence or absent are credible, and our model cannot be used to be sure if a species is present at that location.\nWe‚Äôll load a few helper functions written in a separate file, which will make our implementation of conformal prediction less verbose and easier to understand for those new to Julia.\n\ninclude(\"conformal_prediction.jl\")\n\ncellsize (generic function with 1 method)\n\n\n\nrlevels = LinRange(0.01, 0.2, 100)\nqs = [_estimate_q(dt_sdm, holdout(dt_sdm)...; Œ±=u) for u in rlevels]\nùêè = predict(dt_sdm; threshold=false)\neff = [mean(length.(credibleclasses.(ùêè, q))) for q in qs]\n\n100-element Vector{Float64}:\n 1.918762088974855\n 1.2538684719535784\n 1.918762088974855\n 1.433752417794971\n 1.4700193423597678\n 1.422147001934236\n 1.433752417794971\n 1.422147001934236\n 1.422147001934236\n 1.4700193423597678\n ‚ãÆ\n 0.973404255319149\n 1.0\n 0.973404255319149\n 0.973404255319149\n 1.0\n 1.0\n 1.0\n 1.0\n 0.973404255319149\n\n\n\ncmodel = deepcopy(dt_sdm)\n\ndistrib = predict(cmodel, env_covariates; threshold=true)\nfor i in eachindex(qs)\n    Cp, Ca = credibleclasses(prd, qs[i])\n    undet = .!(Cp .| Ca)\n    sure_presence = Cp .& (.!Ca)\n    unsure = Ca .& Cp\n    unsure_presence = unsure .& distrib\n    unsure_absence = unsure .& (.!distrib)\nend\n\n\n# Cross-conformal with median range selected\nq = median([_estimate_q(cmodel, fold...; Œ±=0.05) for fold in kfold(cmodel; k=10)])\nCp, Ca = credibleclasses(prd, q)\n\n(üó∫Ô∏è  A 240 √ó 546 layer (70065 Bool cells), üó∫Ô∏è  A 240 √ó 546 layer (70065 Bool cells))\n\n\n\nsure_presence = Cp .& (.!Ca)\nsure_absence = Ca .& (.!Cp)\nunsure = Ca .& Cp\nunsure_in = unsure .& distrib\nunsure_out = unsure .& (.!distrib)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Bool cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nFinally, we‚Äôll plot our regions where the conformal model gives only present as credible in green, only absent as credible in light grey, and both as credible (meaning the model is uncertain) is light blue.\n\nf = Figure(; size=(1200, 600))\nax = Axis(f[1:2, 1]; aspect=DataAspect())\npoly!(ax, switzerland, color=:grey95)\nheatmap!(ax, nodata(sure_presence, false), colormap=[:forestgreen])\nheatmap!(ax, nodata(unsure, false), colormap=[(:dodgerblue, 0.3)])\nhidespines!(ax)\nhidedecorations!(ax)\nf"
  },
  {
    "objectID": "index.html#making-a-random-forest-with-bootstrap-aggegration",
    "href": "index.html#making-a-random-forest-with-bootstrap-aggegration",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Making a random forest with Bootstrap Aggegration",
    "text": "Making a random forest with Bootstrap Aggegration\nThe first step toward turning a Decision Tree into a Boosted Regression Tree is bootstrap aggregation (oftened shorted to bagging).\nBagging involves constructing an ensemble model7 from simpler models, where each simpler model is typically trained only on a subset of the features.\n7¬†A ensemble model consists of an average across many models.A random forest (TK CITE) consists of an ensemble of decision trees, each trained on a subset of the features. We construct this by first defining the component model, which is a DecisionTree that first transforms training data with a ZScore\n\nsolo_dt = SDM(ZScore, DecisionTree, env_covariates, presencelayer, pseudoabsences)\n\nSDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.5\n\n\nWe then create an ensemble using the Bagging type, and pass 30 as the total number of component models to use in the ensemble.\n\nrf_sdm = Bagging(solo_dt, 30)\n\n{SDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.5} √ó 30\n\n\nWe then run bagfeatures! to take each component model and choose a subset of variables to train the component model on.\n\nbagfeatures!(rf_sdm)\n\n{SDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.5} √ó 30\n\n\nNow we use train! to fit the ensemble model\n\ntrain!(rf_sdm)\n\n{SDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.414} √ó 30\n\n\n\nprd = predict(rf_sdm, env_covariates; threshold = false)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\nWe can then compute the uncertainty of the model, by considering the inter-quantile-range (iqr, a type of variance), across each component model.\n\nunc = predict(rf_sdm, env_covariates; consensus = iqr, threshold = false)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\n\nf = Figure(; size = (600, 600))\nax = Axis(f[1, 1]; aspect = DataAspect(), title = \"Prediction\")\nhm = heatmap!(ax, prd; colormap = :linear_worb_100_25_c53_n256, colorrange = (0, 1))\nColorbar(f[1, 2], hm)\nlines!(ax, switzerland; color = :black)\nhidedecorations!(ax)\nhidespines!(ax)\nax2 = Axis(f[2, 1]; aspect = DataAspect(), title = \"Uncertainty\")\nhm =\n    heatmap!(ax2, quantize(unc); colormap = :linear_gow_60_85_c27_n256, colorrange = (0, 1))\nColorbar(f[2, 2], hm)\nlines!(ax2, switzerland; color = :black)\nhidedecorations!(ax2)\nhidespines!(ax2)\nf"
  },
  {
    "objectID": "index.html#boosting-to-create-a-brt",
    "href": "index.html#boosting-to-create-a-brt",
    "title": "Interpretable machine learning for species distribution modeling",
    "section": "Boosting to create a BRT",
    "text": "Boosting to create a BRT\nIn a BRT, each component model is boosted.\nBoosting does bagging, but smarter by weighing each sample.\nWe can create a boosted model with the AdaBoost type, with iterations as the number of component models to use.\n\nbst = AdaBoost(dt_sdm; iterations = 50)\n\nAdaBoost {SDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.327} √ó 50 iterations\n\n\n\ntrain!(bst)\n\nAdaBoost {SDeMo.ZScore ‚Üí SDeMo.DecisionTree ‚Üí P(x) ‚â• 0.147} √ó 50 iterations\n\n\n\nbrd = predict(bst, env_covariates; threshold = false)\n\nüó∫Ô∏è  A 240 √ó 546 layer with 70065 Float64 cells\n   Projection: +proj=longlat +datum=WGS84 +no_defs\n\n\n\nfg, ax, pl = heatmap(brd; colormap = :tempo, colorrange = (0, 1))\nax.aspect = DataAspect()\nhidedecorations!(ax)\nhidespines!(ax)\nlines!(ax, switzerland; color = :grey20)\nColorbar(fg[1, 2], pl; height = Relative(0.6))\ncurrent_figure() #hide"
  }
]